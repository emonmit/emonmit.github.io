---
layout: post
title: 批量insert的性能提升
date: 2016-03-24
categories: mysql
tags: [mysql性能优化]
description: 小系统出现性能问题，可能是设计问题；解决了设计问题，应该继续想想，量级再大的话，应该怎么做。
---

随意转载，请注明出处：[http://8.shikun.wang/mysql/2016/03/25/mysql-insert-optimization/](http://8.shikun.wang/mysql/2016/03/25/mysql-insert-optimization/)


## 一个随意的设计

最近调到一个新的部门，一个需求是要在做一个批量发放优惠券的功能，看后台的时候发现已经有了这个功能，询问后发现这个功能跑的时候会挂掉，看了代码之后就了然了：

> - 读取后台上传的文件，将用户手机号拼接成字符串
> - 遍历每个手机号 
> - 根据手机号获取用户uid，带齐参数，调用单用户发放方法
> - Done

看到这里，可能会觉得遍历一遍进行发放是不是很low。嗯，的确是，但当时限制的是`最大1000个`用户的批量发放，1000次就能把程序跑死？在线下环境我把自己的号码跑了1000遍，给了报错提示说的是超时了。把`
max_execution_time`改到了300发现1000次耗时差不多100多秒，这也是产品运营说的没用的原因了，本来觉得既然已经有这个功能。我们把服务器上的配置改下不就行了吗，本以为已经到此为止，产品却说要`支持到10000`的群发，（此处贴个表示开心的图），原来的方式耗时是线性的，扩大10倍的数据量所耗费的时间差不多也会是原来的10倍，具体效果就是产品点完发送之后等菊花图转10几分钟。

不过话说回来产品的要求也不过分，本来老大说要拒绝掉这个需求，只支持到1000的。不过我跟他说改改吧，10000的群发也是很有必要的，用户基数差不多200w，要跟产品说只支持到1000我都不好意思了。现在，我们继续看看原有的代码：

> - 根据优惠券id取得优惠券基本信息
> - 根据用户uid和优惠券id从发放记录里取得用户对这张优惠券的持有量
> - 校验优惠券是否有效（判断个6、7次的样子，期间校验是否超过用户最大持有量）
> - 每一次发放，随机生成一个20位的唯一字符串
> - 插入数据库
> - Done

首先，感到诧异的一个点是每次发放的时候都需要校验优惠券的有效性，但明明对这一批次的用户，都发放的是同一张优化券，显然这就是一个可优化的点，而原来的逻辑只是随意的把这一批次用户当作单个用户来处理。显然，我觉得这样的批量发放并不能称为批量发放。

## 优化批量发放性能

### 改动逻辑

> - 后台上传文件不做处理，只做常规校验
> - 上传成功后在列表中点击*核验*按钮进行**自动核验**
>> **自动核验**会把先将优惠券的有效性、库存等过一遍，然后每个号码遍历一遍，验证是否是正确的手机号、是否是我们的用户（有无uid）、是否超过该优惠券的最大持有量，最终将用户手机号和对应uid写入一份通过核验的名单文档，而不符合要求的写入另一份文档
> - 核验完成后由后台管理人员查看通过和未通过核验的名单，确认改批次是继续*发放*还是*放弃*
> - **确认发放**的话将成功的名单导入，把所有用户拼成一条（不会超过sql最大长度限制）,最后校验一遍优惠券信息后进行发放

把逻辑改成这样之后，首先是减少了之前的冗余操作，看起来至少是更像批量操作了。改成这样之后，**核验10万条数据差不多100秒左右，发送的话20秒**，已经从很大程度上提升了性能，也足以满足产品的需求。

从性能和实际操作的角度来看，最后还是定在了1万，一个是不需要前端进行长时间的等待，一方面也能降低出错概率，也不需要调整线上服务器的配置。**预发布测试结果：核验10000条数据20秒左右，发送需要2秒**。也就是说，单单是逻辑上的这一步整合，就能使这个功能的性能提升了几十倍。

## insert能怎么优化

以上的逻辑优化有一步比较关键的是将多条insert语句合并为1条insert进行插入，这能带来多大的性能提升呢？
先看一份测试数据：

|  数据规模  | 单条插入耗时 | 多条合并插入 |
| ---------- | ------------ | ------------ |
|    100     |    0.148s    |    0.011s    |
|    1000    |    1.227s    |    0.046s    |
|    10000   |    11.648s   |    0.216s    |

可以看出，在批量操作的时候，将多条insert语句合并成一条insert的确可以很大程度上提升性能。那么，为什么这样的改写会使性能发生如此大的变化呢。

> Mysql执行sql时，会写入查询日志，通过合并多条insert语句，变成一条sql，执行时日志量减少了，降低了日志读写磁盘的数据量和频率，从而提高执行效率，另一方面，改成一条sql后，也能减少sql的解析次数

再来看看一次insert都在哪些地方有耗时，数字表示比例：

- 连接 （3）
- 发送查询给服务器 （2）
- 分析查询 （2）
- 插入记录 （1 * 记录大小）
- 插入索引 （1 * 索引）
- 关闭 （1）

可以看出，通过合并多条insert记录，最直接的就是减少了链接和关闭的次数，减少IO操作，总体来说，耗时肯定会是更短的，另外从上面的耗时分析还能看出，索引管理对于批量插入大量数据来说也是个耗时很多的地方。我们可以通过`有序的插入`数据，或者在`插入之前删除索引，插入完成之后重建索引`，来提升这部分的性能。

> 由于数据库插入时，需要维护索引数据，无序的记录会增大维护索引的成本。我们可以参照innodb使用的B+tree索引，如果每次插入记录都在索引的最 后面，索引的定位效率很高，并且对索引调整较小；如果插入的记录在索引中间，需要B+tree进行分裂合并等处理，会消耗比较多计算资源，并且插入记录的索引定位效率会下降，数据量较大时会有频繁的磁盘操作。

### 补充

如果有不适合合并insert的情况，还可以为insert建立事务，这样也能一定程度上提升插入的效率，但是没有合并的效果明显。

> 这是因为进行一个INSERT操作时，MySQL内部会建立一个事务，在事务内才进行真正插入处理操作。通过使用事务可以减少创建事务的消耗，所有插入都在执行后才进行提交操作。

最后再补充几点大牛说的提升insert速度的几个点，学习了再做总结：

> - 通过使用INSERT DELAYED语句得到更高的速度。
> - 当从一个文本文件装载一个表时，使用LOAD DATA INFILE。这通常比使用很多INSERT语句快20倍。
> - 锁定表以加速插入


## 参考资源
- [挽星-mySQL查询优化](http://www.cnblogs.com/younggun/articles/1719943.html)
- [MySQL批量SQL插入性能优化](http://m.oschina.net/blog/296846)
- [yansu.org](http://yansu.org/2014/04/16/insert-large-number-of-data-in-mysql.html)
- [MySQL大数据量快速插入方法和语句优化](http://www.mincoder.com/article/1117.shtml)
